{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/my_drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sptg7D4U4iZP",
        "outputId": "a38b8826-3877-4252-830c-360a3df20459"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/my_drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZjWW9sht9qC",
        "outputId": "59803912-33bf-4bd5-86ff-ec6d57e427c0"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 19 14:21:52 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8              10W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3UXHMoKm_OU",
        "outputId": "112c6e0d-0af0-4882-94ae-951f2dad8df5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatic pdb calling has been turned ON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Import Libraries'''\n",
        "import argparse\n",
        "from argparse import ArgumentParser\n",
        "import glob\n",
        "import cv2\n",
        "import re\n",
        "import random\n",
        "import math\n",
        "import os, glob, datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract, Reshape, Attention\n",
        "from keras.models import Model, load_model\n",
        "from tensorflow.python.keras.utils import conv_utils\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#import data_generator as dg\n",
        "import keras.backend as K\n",
        "import skimage\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.io import imread, imsave\n"
      ],
      "metadata": {
        "id": "E3o4tEiv7SO9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.list_physical_devices('GPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyDLSkA8tUkG",
        "outputId": "eeb03288-456c-481b-d24a-5a50e623bf11"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Set Parameters'''\n",
        "## Params\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--model', default='Deep_DeQuIP', type=str, help='choose a type of model')\n",
        "parser.add_argument('--batch_size', default=10, type=int, help='batch size')\n",
        "\n",
        "parser.add_argument('--train_data_clean', default='/content/my_drive/MyDrive/DIVA-Attention Test/train', type=str, help='path of train data clean')\n",
        "parser.add_argument('--train_data_noisy', default='/content/my_drive/MyDrive/DIVA-Attention Test/bmode', type=str, help='path of train data noisy')\n",
        "\n",
        "parser.add_argument('--kernel_size', default=5, type=int, help='Hamiltonian kernel size')\n",
        "parser.add_argument('--patches_size', default=50, type=int, help='patch size')\n",
        "\n",
        "parser.add_argument('--epoch', default=50, type=int, help='number of train epoches')\n",
        "parser.add_argument('--lr', default=1e-3, type=float, help='initial learning rate for Adam')\n",
        "parser.add_argument('--save_every', default=1, type=int, help='save model at every x epoches')\n",
        "parser.add_argument('-f', '--file', required=False)\n",
        "\n",
        "args = parser.parse_args()\n",
        "#args.save_every = args.epoch\n"
      ],
      "metadata": {
        "id": "XCt7QaeG7UYp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Set Save Dir for Models'''\n",
        "save_dir = os.path.join('/content/my_drive/MyDrive/DIVA-Attention Test',\n",
        "                        args.model+'_Base')\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "  print(save_dir)\n",
        "  os.mkdir(save_dir)\n"
      ],
      "metadata": {
        "id": "NmiWg1vT7Wdb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''utility functions'''\n",
        "\n",
        "def findLastCheckpoint(save_dir):\n",
        "    file_list = glob.glob(os.path.join(save_dir,'model_*.hdf5'))  # returns names of all .hdf5 files\n",
        "    if file_list:\n",
        "        epochs_exist = []\n",
        "        for file in file_list:\n",
        "            result = re.findall(\".*model_(.*).hdf5.*\",file) # returns epoch number from the model checkpoint file\n",
        "            epochs_exist.append(int(result[0]))\n",
        "        initial_epoch=max(epochs_exist)\n",
        "    else:\n",
        "        initial_epoch = 0\n",
        "    return initial_epoch\n",
        "\n",
        "def log(*args,**kwargs):\n",
        "     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"),*args,**kwargs)\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    initial_lr = args.lr\n",
        "    if epoch<=20:\n",
        "        lr = initial_lr\n",
        "    elif epoch<=30:\n",
        "        lr = initial_lr/10\n",
        "    elif epoch<=40:\n",
        "        lr = initial_lr/20\n",
        "    else:\n",
        "        lr = initial_lr/20\n",
        "    log('current learning rate is %2.8f' %lr)\n",
        "    return lr\n"
      ],
      "metadata": {
        "id": "Y-FOVh737hir"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_datagen(epoch_iter=2000, epoch_num=5, batch_size=128, data_dir=args.train_data_noisy):\n",
        "  #Original Batch_size = 128\n",
        "  #Original iter = 2000\n",
        "  n_count = 0 # AneeshFix\n",
        "  while(True):\n",
        "      # n_count = 0 AneeshError\n",
        "      if n_count == 0:\n",
        "          #print(n_count)\n",
        "          #xs, ys = speckled_datagenerator(data_dir)  AneeshError?  # generate clean and noisy data\n",
        "          clean_data, noisy_data = speckled_datagenerator(data_dir) #AneeshFix\n",
        "\n",
        "          assert len(clean_data) % args.batch_size == 0, 'make sure the last iteration has a full batchsize, this is important if you use batch normalization!'\n",
        "\n",
        "          # normalize the pixel values between 0 and 1\n",
        "          clean_data = clean_data.astype('float32')/255.0\n",
        "          noisy_data = noisy_data.astype('float32')/255.0\n",
        "\n",
        "          indices = list(range(clean_data.shape[0]))\n",
        "          n_count = 1\n",
        "\n",
        "      for _ in range(epoch_num):\n",
        "          np.random.shuffle(indices)\n",
        "          for i in range(0, len(indices), batch_size):\n",
        "              clean_batch = clean_data[indices[i:i+batch_size]]\n",
        "              noisy_batch = noisy_data[indices[i:i+batch_size]]\n",
        "\n",
        "             # noise =  np.random.normal(0, args.sigma/255.0, batch_x.shape)\n",
        "\n",
        "              yield noisy_batch, clean_batch"
      ],
      "metadata": {
        "id": "7EQ-hhQT8Xoq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_batch(data):\n",
        "  data = np.array(data, dtype='uint8')\n",
        "  data = data.reshape((data.shape[0]*data.shape[1],data.shape[2],data.shape[3],1))\n",
        "  discard_n = len(data)-len(data) // batch_size*batch_size\n",
        "  data = np.delete(data, range(discard_n), axis = 0)\n",
        "  return data"
      ],
      "metadata": {
        "id": "bHKYgBMZrLkd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def speckled_datagenerator(data_dir, verbose=False):\n",
        "\n",
        "    file_list = glob.glob(data_dir+'/*.png')  # returns names of all .png files in B_Mode Dir\n",
        "    #print('file_list', file_list)\n",
        "\n",
        "    data = []\n",
        "    data_clean = []\n",
        "\n",
        "    # generate patches for all images in the directory\n",
        "    for i in range(len(file_list)):\n",
        "        clean_patch, patch = gen_speckled_image_patches(file_list[i])\n",
        "\n",
        "        data.append(patch)\n",
        "        data_clean.append(clean_patch)\n",
        "\n",
        "        if verbose:\n",
        "            print('image :',str(i+1)+'/'+ str(len(file_list)))\n",
        "\n",
        "    # do for speckled data\n",
        "    data = np.array(data, dtype='uint8')\n",
        "    data = data.reshape((data.shape[0]*data.shape[1],data.shape[2],data.shape[3],1))\n",
        "    discard_n = len(data)-len(data)//batch_size*batch_size\n",
        "    data = np.delete(data,range(discard_n),axis = 0)\n",
        "\n",
        "    # do for clean data\n",
        "    data_clean = np.array(data_clean, dtype='uint8')\n",
        "    data_clean = data_clean.reshape((data_clean.shape[0]*data_clean.shape[1],data_clean.shape[2],data_clean.shape[3],1))\n",
        "    discard_n = len(data_clean)-len(data_clean)//batch_size*batch_size\n",
        "    data_clean = np.delete(data_clean,range(discard_n),axis = 0)\n",
        "\n",
        "    print('-----training data finished-----')\n",
        "    print('noisy image shape:',data.shape)\n",
        "    print('clean image shape:',data_clean.shape)\n",
        "\n",
        "    assert data.shape == data_clean.shape\n",
        "\n",
        "\n",
        "    return data_clean, data"
      ],
      "metadata": {
        "id": "yi_PY1bO7vhz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def gen_speckled_image_patches(file_name):\n",
        "\n",
        "    last_name = file_name.split('_')[-1] #  Returns Name of the Image\n",
        "    clean_image_file_name = os.path.join(args.train_data_clean, last_name) # clean train image directory\n",
        "\n",
        "    img = cv2.imread(file_name, 0) # noisy image\n",
        "    clean_img = cv2.imread(clean_image_file_name, 0) # clean image\n",
        "\n",
        "    '''show(np.hstack((clean_img,img))) # display the images'''\n",
        "\n",
        "    h, w = img.shape\n",
        "\n",
        "    patches = []\n",
        "    clean_patches = []\n",
        "\n",
        "    for s in scales: # scaling the images\n",
        "        h_scaled, w_scaled = int(h*s),int(w*s)\n",
        "        img_scaled = cv2.resize(img, (h_scaled,w_scaled), interpolation=cv2.INTER_CUBIC)\n",
        "        clean_img_scaled = cv2.resize(clean_img, (h_scaled,w_scaled), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        # extract patches from the images '''ANEESH: PATCH 1 GETTING GENERATED'''\n",
        "        for i in range(0, h_scaled-patch_size+1, stride):\n",
        "            for j in range(0, w_scaled-patch_size+1, stride):\n",
        "                patch = img_scaled[i:i+patch_size, j:j+patch_size]\n",
        "                clean_patch = clean_img_scaled[i:i+patch_size, j:j+patch_size]\n",
        "\n",
        "                # data augmentation\n",
        "                for k in range(0, aug_times):\n",
        "                  mode_k=np.random.randint(0,8)\n",
        "                  patch_aug = data_augmentation(patch, mode=mode_k)\n",
        "                  clean_patch_aug = data_augmentation(clean_patch, mode=mode_k)\n",
        "                  patches.append(patch_aug)\n",
        "                  clean_patches.append(clean_patch_aug)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return clean_patches, patches"
      ],
      "metadata": {
        "id": "6ktmhpD-8xur"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Data Augmentation'''\n",
        "def data_augmentation(img, mode=0):\n",
        "    if mode == 0:\n",
        "        return img\n",
        "    elif mode == 1:\n",
        "        return np.flipud(img)\n",
        "    elif mode == 2:\n",
        "        return np.rot90(img)\n",
        "    elif mode == 3:\n",
        "        return np.flipud(np.rot90(img))\n",
        "    elif mode == 4:\n",
        "        return np.rot90(img, k=2)\n",
        "    elif mode == 5:\n",
        "        return np.flipud(np.rot90(img, k=2))\n",
        "    elif mode == 6:\n",
        "        return np.rot90(img, k=3)\n",
        "    elif mode == 7:\n",
        "        return np.flipud(np.rot90(img, k=3))"
      ],
      "metadata": {
        "id": "UAKj62Vp8bXU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "'''Show Images'''\n",
        "def show(x,title=None,cbar=False,figsize=None):\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(x,interpolation='nearest',cmap='gray')\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    if cbar:\n",
        "        plt.colorbar()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "KHhB2Ggv70Fd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Loss Function'''\n",
        "def sum_squared_error(y_true, y_pred):\n",
        "    #return K.mean(K.square(y_pred - y_true), axis=-1)\n",
        "    #return K.sum(K.square(y_pred - y_true), axis=-1)/2\n",
        "    return K.sum(K.square(y_pred - y_true))/2"
      ],
      "metadata": {
        "id": "uCsHTWNK78rr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''DIVA2D Model'''\n",
        "def DIVA2D(depth,filters=64,image_channels=1, kernel_size=5, use_bnorm=True):\n",
        "    layer_count = 0\n",
        "    inpt = Input(shape=(None,None,image_channels),name = 'input'+str(layer_count))\n",
        "\n",
        "    # Get the initial patches /initial_patches '''ANEESH: SMALLER PATCHES GENERATED FROM BIGGER PATCHES BY GENERATE_PATCH FUNCTION, IMAGE DIMENSION REMAINS SAME'''\n",
        "    initial_patches = Conv2D(filters=filters, kernel_size=(kernel_size,kernel_size), strides=(1,1),kernel_initializer='Orthogonal', padding='same',name = 'initial_patches')(inpt)\n",
        "    initial_patches = Activation('relu',name = 'initial_patch_acti')(initial_patches)\n",
        "    #print(initial_patches.get_shape())\n",
        "\n",
        "\n",
        "\n",
        "    # interaction layer ANEESH: REPLACE BY ATTENTION? PREPEND / APPEND ATTENTION?\n",
        "    inter = Conv2D(filters=filters, kernel_size=(kernel_size,kernel_size), strides=(1,1),kernel_initializer='Orthogonal', padding='same',name = 'interactions')(initial_patches)\n",
        "    inter = Activation('relu',name = 'interaction_acti'+str(layer_count))(inter)\n",
        "    #print(inter.get_shape())\n",
        "\n",
        "    # Get contributions of the original potential in the Hamiltonian kernel ANEESH: Ja from DIVA Diagram\n",
        "    ori_poten_kernel = tf.keras.layers.MaxPooling2D (pool_size=(21,21), strides=(15,15), padding='same', name = 'ori_poten_ker', data_format=None )(initial_patches)\n",
        "    #print('ori_poten_kernel',ori_poten_kernel.get_shape())\n",
        "\n",
        "    # Get contributions of the interactions in the Hamiltonian kernel ANEESH: Ia from DIVA Diagram\n",
        "    inter_kernel = tf.keras.layers.MaxPooling2D (pool_size=(21,21), strides=(15,15), padding='same', name = 'inter_ker', data_format=None )(inter)\n",
        "    #print('inter_kernel',inter_kernel.get_shape())\n",
        "\n",
        "\n",
        "    # Get projection coefficients of the initial patches on the Hamiltonian kernel\n",
        "    x = Hamiltonian_Conv2D(filters=filters, kernel_size=(kernel_size,kernel_size), kernel_3 = ori_poten_kernel, kernel_4 = inter_kernel, strides=(1,1), activation='relu',\n",
        "                              kernel_initializer='Orthogonal', padding='same', name = 'proj_coef')(initial_patches)\n",
        "\n",
        "    #print('coef',x.get_shape())\n",
        "\n",
        "\n",
        "    # Do Thresholding (depth depends on the noise intensity)\n",
        "    for i in range(depth):\n",
        "      layer_count += 1\n",
        "      x = Conv2D(filters=filters, kernel_size=(kernel_size,kernel_size), strides=(1,1),kernel_initializer='Orthogonal', padding='same',use_bias = False,name = 'conv'+str(layer_count))(x)\n",
        "\n",
        "      layer_count += 1\n",
        "      x = BatchNormalization(axis=3, momentum=0.1,epsilon=0.0001, name = 'bn'+str(layer_count))(x)\n",
        "        #x = BatchNormalization(axis=3, momentum=0.0,epsilon=0.0001, name = 'bn'+str(layer_count))(x)\n",
        "\n",
        "      # Thresholding\n",
        "      x = Activation('relu',name = 'Thresholding'+str(layer_count))(x)\n",
        "\n",
        "    # Inverse projection\n",
        "    x = Conv2D(filters=image_channels, kernel_size=(kernel_size,kernel_size), strides=(1,1), kernel_initializer='Orthogonal',padding='same',use_bias = False,name = 'inv_trans')(x)\n",
        "\n",
        "\n",
        "    # Deconvolution layer ANEESH: NEUTRALIZATION LAYER SIMILAR TO DIVA-A?\n",
        "    layer_count += 1\n",
        "    x = Conv2D(filters=filters, kernel_size=(args.kernel_size,args.kernel_size), strides=(1,1), kernel_initializer='Orthogonal',padding='same',use_bias = False,name = 'deconv'+str(layer_count))(x)\n",
        "    layer_count += 1\n",
        "    x = Conv2D(filters=filters, kernel_size=(args.kernel_size,args.kernel_size), strides=(1,1), kernel_initializer='Orthogonal',padding='same',use_bias = False,name = 'deconv'+str(layer_count))(x)\n",
        "    layer_count += 1\n",
        "    x = Conv2D(filters=image_channels, kernel_size=(args.kernel_size,args.kernel_size), strides=(1,1), kernel_initializer='Orthogonal',padding='same',use_bias = False,name = 'deconv'+str(layer_count))(x)\n",
        "    layer_count += 1\n",
        "\n",
        "\n",
        "    x = Subtract(name = 'subtract')([inpt, x])   # input - noise '''ANEESH: Noisy Image is getting subtracted from the Denoised Image'''\n",
        "\n",
        "    model = Model(inputs=inpt, outputs=x)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "TJOxFp6R76eh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "89Ajlpp5ueWM"
      },
      "outputs": [],
      "source": [
        " '''Hamiltonian convolution layer'''\n",
        "class Hamiltonian_Conv2D(Conv2D):\n",
        "\n",
        "    def __init__(self, filters, kernel_size, kernel_3=None, kernel_4=None, activation=None, use_bias = False, **kwargs):\n",
        "\n",
        "        self.rank = 2               # Dimension of the kernel\n",
        "        self.num_filters = filters  # Number of filter in the convolution layer\n",
        "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, self.rank, 'kernel_size')\n",
        "        self.kernel_3 = kernel_3    # Weights from original potential\n",
        "        self.kernel_4 = kernel_4    # Weights from interaction\n",
        "\n",
        "        super(Hamiltonian_Conv2D, self).__init__(self.num_filters, self.kernel_size,\n",
        "              activation=activation, use_bias=False, **kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "        if input_shape[channel_axis] is None:\n",
        "            raise ValueError('The channel dimension of the inputs '\n",
        "                     'should be defined. Found `None`.')\n",
        "\n",
        "        #don't use bias:\n",
        "        self.bias = None\n",
        "\n",
        "        #consider the layer built\n",
        "        self.built = True\n",
        "\n",
        "\n",
        "        # Define nabla operator\n",
        "        weights_1 = tf.constant([[ 2.,-1., 0.],\n",
        "                                 [-1., 4.,-1.],\n",
        "                                 [ 0.,-1., 2.]])\n",
        "\n",
        "\n",
        "        weights_1 = tf.reshape(weights_1 , [3,3, 1])\n",
        "        weights_1 = tf.repeat(weights_1 , repeats=self.num_filters, axis=2)\n",
        "        #print('kernel shape of weights_1:',weights_1.get_shape())\n",
        "\n",
        "        # Define Weights for h^2/2m  (size should be same as the nabla operator)\n",
        "        weights_2 = self.add_weight(shape=weights_1.get_shape(),\n",
        "                                      initializer= 'Orthogonal',\n",
        "                                      name='kernel_h^2/2m',\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        #print('kernel shape of weights_2:',weights_2.get_shape())\n",
        "\n",
        "\n",
        "        # Define the Hamiltonian kernel\n",
        "        self.kernel = weights_1*weights_2 + self.kernel_3 + self.kernel_4\n",
        "        #print('self.kernel',self.kernel.get_shape())\n",
        "\n",
        "        self.built = True\n",
        "        super(Hamiltonian_Conv2D, self).build(input_shape)\n",
        "\n",
        "    # Do the 2D convolution using the Hamiltonian kernel\n",
        "    def convolution_op(self, inputs, kernel):\n",
        "        if self.padding == \"causal\":\n",
        "            tf_padding = \"VALID\"  # Causal padding handled in `call`.\n",
        "        elif isinstance(self.padding, str):\n",
        "            tf_padding = self.padding.upper()\n",
        "        else:\n",
        "            tf_padding = self.padding\n",
        "\n",
        "\n",
        "        return tf.nn.convolution(\n",
        "            inputs,\n",
        "            kernel,\n",
        "            strides=list(self.strides),\n",
        "            padding=tf_padding,\n",
        "            dilations=list(self.dilation_rate),\n",
        "            name=self.__class__.__name__,\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        outputs = self.convolution_op(inputs, self.kernel)\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = DIVA2D(depth=15,filters=96,image_channels=1,use_bnorm=True)"
      ],
      "metadata": {
        "id": "oz0OteFv6AoF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "aNIHpeSg6KEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ecac886d-e891-4ffc-d3cf-4999c17f38dd"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input0 (InputLayer)         [(None, None, None, 1)]      0         []                            \n",
            "                                                                                                  \n",
            " initial_patches (Conv2D)    (None, None, None, 96)       2496      ['input0[0][0]']              \n",
            "                                                                                                  \n",
            " initial_patch_acti (Activa  (None, None, None, 96)       0         ['initial_patches[0][0]']     \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " proj_coef (Hamiltonian_Con  (None, None, None, 96)       231264    ['initial_patch_acti[0][0]']  \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv1 (Conv2D)              (None, None, None, 96)       230400    ['proj_coef[0][0]']           \n",
            "                                                                                                  \n",
            " bn2 (BatchNormalization)    (None, None, None, 96)       384       ['conv1[0][0]']               \n",
            "                                                                                                  \n",
            " Thresholding2 (Activation)  (None, None, None, 96)       0         ['bn2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv3 (Conv2D)              (None, None, None, 96)       230400    ['Thresholding2[0][0]']       \n",
            "                                                                                                  \n",
            " bn4 (BatchNormalization)    (None, None, None, 96)       384       ['conv3[0][0]']               \n",
            "                                                                                                  \n",
            " Thresholding4 (Activation)  (None, None, None, 96)       0         ['bn4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv5 (Conv2D)              (None, None, None, 96)       230400    ['Thresholding4[0][0]']       \n",
            "                                                                                                  \n",
            " bn6 (BatchNormalization)    (None, None, None, 96)       384       ['conv5[0][0]']               \n",
            "                                                                                                  \n",
            " Thresholding6 (Activation)  (None, None, None, 96)       0         ['bn6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv7 (Conv2D)              (None, None, None, 96)       230400    ['Thresholding6[0][0]']       \n",
            "                                                                                                  \n",
            " bn8 (BatchNormalization)    (None, None, None, 96)       384       ['conv7[0][0]']               \n",
            "                                                                                                  \n",
            " Thresholding8 (Activation)  (None, None, None, 96)       0         ['bn8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv9 (Conv2D)              (None, None, None, 96)       230400    ['Thresholding8[0][0]']       \n",
            "                                                                                                  \n",
            " bn10 (BatchNormalization)   (None, None, None, 96)       384       ['conv9[0][0]']               \n",
            "                                                                                                  \n",
            " Thresholding10 (Activation  (None, None, None, 96)       0         ['bn10[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv11 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding10[0][0]']      \n",
            "                                                                                                  \n",
            " bn12 (BatchNormalization)   (None, None, None, 96)       384       ['conv11[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding12 (Activation  (None, None, None, 96)       0         ['bn12[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv13 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding12[0][0]']      \n",
            "                                                                                                  \n",
            " bn14 (BatchNormalization)   (None, None, None, 96)       384       ['conv13[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding14 (Activation  (None, None, None, 96)       0         ['bn14[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv15 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding14[0][0]']      \n",
            "                                                                                                  \n",
            " bn16 (BatchNormalization)   (None, None, None, 96)       384       ['conv15[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding16 (Activation  (None, None, None, 96)       0         ['bn16[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv17 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding16[0][0]']      \n",
            "                                                                                                  \n",
            " bn18 (BatchNormalization)   (None, None, None, 96)       384       ['conv17[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding18 (Activation  (None, None, None, 96)       0         ['bn18[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv19 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding18[0][0]']      \n",
            "                                                                                                  \n",
            " bn20 (BatchNormalization)   (None, None, None, 96)       384       ['conv19[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding20 (Activation  (None, None, None, 96)       0         ['bn20[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv21 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding20[0][0]']      \n",
            "                                                                                                  \n",
            " bn22 (BatchNormalization)   (None, None, None, 96)       384       ['conv21[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding22 (Activation  (None, None, None, 96)       0         ['bn22[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv23 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding22[0][0]']      \n",
            "                                                                                                  \n",
            " bn24 (BatchNormalization)   (None, None, None, 96)       384       ['conv23[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding24 (Activation  (None, None, None, 96)       0         ['bn24[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv25 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding24[0][0]']      \n",
            "                                                                                                  \n",
            " bn26 (BatchNormalization)   (None, None, None, 96)       384       ['conv25[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding26 (Activation  (None, None, None, 96)       0         ['bn26[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv27 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding26[0][0]']      \n",
            "                                                                                                  \n",
            " bn28 (BatchNormalization)   (None, None, None, 96)       384       ['conv27[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding28 (Activation  (None, None, None, 96)       0         ['bn28[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv29 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding28[0][0]']      \n",
            "                                                                                                  \n",
            " bn30 (BatchNormalization)   (None, None, None, 96)       384       ['conv29[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding30 (Activation  (None, None, None, 96)       0         ['bn30[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inv_trans (Conv2D)          (None, None, None, 1)        2400      ['Thresholding30[0][0]']      \n",
            "                                                                                                  \n",
            " deconv31 (Conv2D)           (None, None, None, 96)       2400      ['inv_trans[0][0]']           \n",
            "                                                                                                  \n",
            " deconv32 (Conv2D)           (None, None, None, 96)       230400    ['deconv31[0][0]']            \n",
            "                                                                                                  \n",
            " deconv33 (Conv2D)           (None, None, None, 1)        2400      ['deconv32[0][0]']            \n",
            "                                                                                                  \n",
            " subtract (Subtract)         (None, None, None, 1)        0         ['input0[0][0]',              \n",
            "                                                                     'deconv33[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 3933120 (15.00 MB)\n",
            "Trainable params: 3930240 (14.99 MB)\n",
            "Non-trainable params: 2880 (11.25 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Hyperparameters'''\n",
        "patch_size, stride = 50, 10\n",
        "aug_times = 1\n",
        "scales = [1] # [1, 0.9, 0.8, 0.7]\n",
        "batch_size = 10"
      ],
      "metadata": {
        "id": "P5k_OuLm7o6H"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # model selection\n",
        "    model = DIVA2D(depth=15,filters=96,image_channels=1,use_bnorm=True)\n",
        "    #model.summary()\n",
        "\n",
        "    # load the last model in matconvnet style\n",
        "    initial_epoch = findLastCheckpoint(save_dir=save_dir)\n",
        "    if initial_epoch > 0:\n",
        "        print('resuming by loading epoch %03d'%initial_epoch)\n",
        "        model.load_weights(os.path.join(save_dir,'model_%03d.hdf5'%initial_epoch))\n",
        "\n",
        "    # compile the model\n",
        "    model.compile(optimizer=Adam(0.001), loss= tf.keras.losses.MeanSquaredError(), #tf.keras.losses.CosineSimilarity (axis=-1, reduction=\"auto\", name=\"cosine_similarity\"),\n",
        "                  metrics=[tf.keras.metrics.MeanSquaredError(),\n",
        "                           tf.keras.metrics.RootMeanSquaredError(),\n",
        "                           tf.keras.metrics.MeanSquaredLogarithmicError(),\n",
        "                           tf.keras.metrics.MeanAbsoluteError(),\n",
        "                           sum_squared_error])\n",
        "\n",
        "    # tf.keras.metrics.MeanAbsolutePercentageError(), tf.keras.metrics.CosineSimilarity(name=\"cosine_similarity\", dtype=None, axis=-1),\n",
        "    # tf.keras.metrics.LogCoshError(),\n",
        "\n",
        "    # use call back functions\n",
        "    checkpointer = ModelCheckpoint(os.path.join(save_dir,'model_{epoch:03d}.hdf5'),\n",
        "                verbose=1, save_weights_only=False, period=1)\n",
        "    csv_logger = CSVLogger(os.path.join(save_dir,'log.csv'), append=True, separator=',')\n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "    print('batch_size = ',args.batch_size)\n",
        "    history = model.fit(train_datagen(batch_size=args.batch_size),\n",
        "                steps_per_epoch=1500, epochs=5, verbose=1, initial_epoch=initial_epoch,\n",
        "                callbacks=[checkpointer,csv_logger,lr_scheduler])\n",
        "    #steps_per_epoch = 7000, epochs = 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxqNGvHd7-zY",
        "outputId": "edf9612e-e7f1-4c39-a0e6-97d026014d28"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size =  10\n",
            "-----training data finished-----\n",
            "noisy image shape: (13690, 50, 50, 1)\n",
            "clean image shape: (13690, 50, 50, 1)\n",
            "2024-04-19 15:40:52: current learning rate is 0.00100000\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['proj_coef/kernel_h^2/2m:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['proj_coef/kernel_h^2/2m:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['proj_coef/kernel_h^2/2m:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['proj_coef/kernel_h^2/2m:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1500/1500 [==============================] - ETA: 0s - loss: 0.4267 - mean_squared_error: 0.4267 - root_mean_squared_error: 0.6532 - mean_squared_logarithmic_error: 0.0163 - mean_absolute_error: 0.1332 - sum_squared_error: 5333.5332\n",
            "Epoch 1: saving model to /content/my_drive/MyDrive/DIVA-Attention Test/Deep_DeQuIP_Base/model_001.hdf5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1500/1500 [==============================] - 171s 103ms/step - loss: 0.4267 - mean_squared_error: 0.4267 - root_mean_squared_error: 0.6532 - mean_squared_logarithmic_error: 0.0163 - mean_absolute_error: 0.1332 - sum_squared_error: 5333.5332 - lr: 0.0010\n",
            "2024-04-19 15:43:43: current learning rate is 0.00100000\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - ETA: 0s - loss: 0.0192 - mean_squared_error: 0.0192 - root_mean_squared_error: 0.1385 - mean_squared_logarithmic_error: 0.0109 - mean_absolute_error: 0.1082 - sum_squared_error: 239.8564\n",
            "Epoch 2: saving model to /content/my_drive/MyDrive/DIVA-Attention Test/Deep_DeQuIP_Base/model_002.hdf5\n",
            "1500/1500 [==============================] - 153s 102ms/step - loss: 0.0192 - mean_squared_error: 0.0192 - root_mean_squared_error: 0.1385 - mean_squared_logarithmic_error: 0.0109 - mean_absolute_error: 0.1082 - sum_squared_error: 239.8564 - lr: 0.0010\n",
            "2024-04-19 15:46:16: current learning rate is 0.00100000\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - ETA: 0s - loss: 0.0168 - mean_squared_error: 0.0168 - root_mean_squared_error: 0.1295 - mean_squared_logarithmic_error: 0.0096 - mean_absolute_error: 0.1001 - sum_squared_error: 209.6965\n",
            "Epoch 3: saving model to /content/my_drive/MyDrive/DIVA-Attention Test/Deep_DeQuIP_Base/model_003.hdf5\n",
            "1500/1500 [==============================] - 153s 102ms/step - loss: 0.0168 - mean_squared_error: 0.0168 - root_mean_squared_error: 0.1295 - mean_squared_logarithmic_error: 0.0096 - mean_absolute_error: 0.1001 - sum_squared_error: 209.6965 - lr: 0.0010\n",
            "2024-04-19 15:48:49: current learning rate is 0.00100000\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - ETA: 0s - loss: 0.0124 - mean_squared_error: 0.0124 - root_mean_squared_error: 0.1113 - mean_squared_logarithmic_error: 0.0072 - mean_absolute_error: 0.0841 - sum_squared_error: 154.9358\n",
            "Epoch 4: saving model to /content/my_drive/MyDrive/DIVA-Attention Test/Deep_DeQuIP_Base/model_004.hdf5\n",
            "1500/1500 [==============================] - 153s 102ms/step - loss: 0.0124 - mean_squared_error: 0.0124 - root_mean_squared_error: 0.1113 - mean_squared_logarithmic_error: 0.0072 - mean_absolute_error: 0.0841 - sum_squared_error: 154.9358 - lr: 0.0010\n",
            "2024-04-19 15:51:22: current learning rate is 0.00100000\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - ETA: 0s - loss: 0.0103 - mean_squared_error: 0.0103 - root_mean_squared_error: 0.1017 - mean_squared_logarithmic_error: 0.0060 - mean_absolute_error: 0.0758 - sum_squared_error: 129.2671\n",
            "Epoch 5: saving model to /content/my_drive/MyDrive/DIVA-Attention Test/Deep_DeQuIP_Base/model_005.hdf5\n",
            "1500/1500 [==============================] - 153s 102ms/step - loss: 0.0103 - mean_squared_error: 0.0103 - root_mean_squared_error: 0.1017 - mean_squared_logarithmic_error: 0.0060 - mean_absolute_error: 0.0758 - sum_squared_error: 129.2671 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''saves the history of the model as a binary file'''\n",
        "import pickle\n",
        "\n",
        "# Save history to a file\n",
        "with open('/content/my_drive/MyDrive/CNRS Research/Deep_DeQuIP_100_F/training_history.pkl', 'wb') as file:\n",
        "    pickle.dump(history.history, file)"
      ],
      "metadata": {
        "id": "h3AhxsrTlJXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for loss\n",
        "#plt.plot((history.history['loss']))\n",
        "plt.plot((history.history['mean_squared_error']))\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()\n",
        "#1622.84 min sum_square_error -> v1 train 50 epoch, 2500 steps, 256 batches"
      ],
      "metadata": {
        "id": "L38p0S5rwJy_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "outputId": "d7a22e72-5085-46a8-e9fd-5b2be4a01aff"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'mean_squared_error', 'root_mean_squared_error', 'mean_squared_logarithmic_error', 'mean_absolute_error', 'sum_squared_error', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "9PnoCdQIgIqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0OBooABHuWW_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}