{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ZjWW9sht9qC",
        "outputId": "9ff4c280-7817-4d92-d1dc-c3b7173fc417"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fri Apr 19 14:46:44 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   74C    P8              11W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%pdb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E3UXHMoKm_OU",
        "outputId": "4b4234c4-0d90-430b-cdc3-7f0198c594b1"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Automatic pdb calling has been turned ON\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Import Libraries'''\n",
        "import argparse\n",
        "from argparse import ArgumentParser\n",
        "import glob\n",
        "import cv2\n",
        "import re\n",
        "import random\n",
        "import math\n",
        "import os, glob, datetime\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "\n",
        "from keras.layers import  Input,Conv2D,BatchNormalization,Activation,Subtract, Reshape, Attention, MaxPooling2D,LayerNormalization\n",
        "from keras.models import Model, load_model\n",
        "from tensorflow.python.keras.utils import conv_utils\n",
        "from keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "\n",
        "#import data_generator as dg\n",
        "import keras.backend as K\n",
        "import skimage\n",
        "from skimage.metrics import structural_similarity as ssim\n",
        "from skimage.io import imread, imsave\n"
      ],
      "metadata": {
        "id": "E3o4tEiv7SO9"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.config.experimental.list_physical_devices('GPU')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jyDLSkA8tUkG",
        "outputId": "f961428b-eb6f-487d-a4cd-e86543476ef9"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Set Parameters'''\n",
        "## Params\n",
        "parser = argparse.ArgumentParser()\n",
        "parser.add_argument('--model', default='Deep_DeQuIP', type=str, help='choose a type of model')\n",
        "parser.add_argument('--batch_size', default=10, type=int, help='batch size')\n",
        "\n",
        "parser.add_argument('--train_data_clean', default='/content/my_drive/MyDrive/DIVA-Attention Test/train', type=str, help='path of train data clean')\n",
        "parser.add_argument('--train_data_noisy', default='/content/my_drive/MyDrive/DIVA-Attention Test/bmode', type=str, help='path of train data noisy')\n",
        "\n",
        "parser.add_argument('--kernel_size', default=5, type=int, help='Hamiltonian kernel size')\n",
        "parser.add_argument('--patches_size', default=50, type=int, help='patch size')\n",
        "\n",
        "parser.add_argument('--epoch', default=50, type=int, help='number of train epoches')\n",
        "parser.add_argument('--lr', default=1e-3, type=float, help='initial learning rate for Adam')\n",
        "parser.add_argument('--save_every', default=1, type=int, help='save model at every x epoches')\n",
        "parser.add_argument('-f', '--file', required=False)\n",
        "\n",
        "args = parser.parse_args()\n",
        "#args.save_every = args.epoch\n"
      ],
      "metadata": {
        "id": "XCt7QaeG7UYp"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Set Save Dir for Models'''\n",
        "save_dir = os.path.join('/content/my_drive/MyDrive/DIVA-Attention Test',\n",
        "                        args.model+'_Attn')\n",
        "\n",
        "if not os.path.exists(save_dir):\n",
        "  print(save_dir)\n",
        "  os.mkdir(save_dir)\n"
      ],
      "metadata": {
        "id": "NmiWg1vT7Wdb"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''utility functions'''\n",
        "\n",
        "def findLastCheckpoint(save_dir):\n",
        "    file_list = glob.glob(os.path.join(save_dir,'model_*.hdf5'))  # returns names of all .hdf5 files\n",
        "    if file_list:\n",
        "        epochs_exist = []\n",
        "        for file in file_list:\n",
        "            result = re.findall(\".*model_(.*).hdf5.*\",file) # returns epoch number from the model checkpoint file\n",
        "            epochs_exist.append(int(result[0]))\n",
        "        initial_epoch=max(epochs_exist)\n",
        "    else:\n",
        "        initial_epoch = 0\n",
        "    return initial_epoch\n",
        "\n",
        "def log(*args,**kwargs):\n",
        "     print(datetime.datetime.now().strftime(\"%Y-%m-%d %H:%M:%S:\"),*args,**kwargs)\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    initial_lr = args.lr\n",
        "    if epoch<=20:\n",
        "        lr = initial_lr\n",
        "    elif epoch<=30:\n",
        "        lr = initial_lr/10\n",
        "    elif epoch<=40:\n",
        "        lr = initial_lr/20\n",
        "    else:\n",
        "        lr = initial_lr/20\n",
        "    log('current learning rate is %2.8f' %lr)\n",
        "    return lr\n"
      ],
      "metadata": {
        "id": "Y-FOVh737hir"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_datagen(epoch_iter=2000, epoch_num=5, batch_size=128, data_dir=args.train_data_noisy):\n",
        "  #Original Batch_size = 128\n",
        "  #Original iter = 2000\n",
        "  n_count = 0 # AneeshFix\n",
        "  while(True):\n",
        "      # n_count = 0 AneeshError\n",
        "      if n_count == 0:\n",
        "          #print(n_count)\n",
        "          #xs, ys = speckled_datagenerator(data_dir)  AneeshError?  # generate clean and noisy data\n",
        "          clean_data, noisy_data = speckled_datagenerator(data_dir) #AneeshFix\n",
        "\n",
        "          assert len(clean_data) % args.batch_size == 0, 'make sure the last iteration has a full batchsize, this is important if you use batch normalization!'\n",
        "\n",
        "          # normalize the pixel values between 0 and 1\n",
        "          clean_data = clean_data.astype('float32')/255.0\n",
        "          noisy_data = noisy_data.astype('float32')/255.0\n",
        "\n",
        "          indices = list(range(clean_data.shape[0]))\n",
        "          n_count = 1\n",
        "\n",
        "      for _ in range(epoch_num):\n",
        "          np.random.shuffle(indices)\n",
        "          for i in range(0, len(indices), batch_size):\n",
        "              clean_batch = clean_data[indices[i:i+batch_size]]\n",
        "              noisy_batch = noisy_data[indices[i:i+batch_size]]\n",
        "\n",
        "             # noise =  np.random.normal(0, args.sigma/255.0, batch_x.shape)\n",
        "\n",
        "              yield noisy_batch, clean_batch"
      ],
      "metadata": {
        "id": "7EQ-hhQT8Xoq"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_batch(data):\n",
        "  data = np.array(data, dtype='uint8')\n",
        "  data = data.reshape((data.shape[0]*data.shape[1],data.shape[2],data.shape[3],1))\n",
        "  discard_n = len(data)-len(data) // batch_size*batch_size\n",
        "  data = np.delete(data, range(discard_n), axis = 0)\n",
        "  return data"
      ],
      "metadata": {
        "id": "bHKYgBMZrLkd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def speckled_datagenerator(data_dir, verbose=False):\n",
        "\n",
        "    file_list = glob.glob(data_dir+'/*.png')  # returns names of all .png files in B_Mode Dir\n",
        "    #print('file_list', file_list)\n",
        "\n",
        "    data = []\n",
        "    data_clean = []\n",
        "\n",
        "    # generate patches for all images in the directory\n",
        "    for i in range(len(file_list)):\n",
        "        clean_patch, patch = gen_speckled_image_patches(file_list[i])\n",
        "\n",
        "        data.append(patch)\n",
        "        data_clean.append(clean_patch)\n",
        "\n",
        "        if verbose:\n",
        "            print('image :',str(i+1)+'/'+ str(len(file_list)))\n",
        "\n",
        "    # do for speckled data\n",
        "    data = np.array(data, dtype='uint8')\n",
        "    data = data.reshape((data.shape[0]*data.shape[1],data.shape[2],data.shape[3],1))\n",
        "    discard_n = len(data)-len(data)//batch_size*batch_size\n",
        "    data = np.delete(data,range(discard_n),axis = 0)\n",
        "\n",
        "    # do for clean data\n",
        "    data_clean = np.array(data_clean, dtype='uint8')\n",
        "    data_clean = data_clean.reshape((data_clean.shape[0]*data_clean.shape[1],data_clean.shape[2],data_clean.shape[3],1))\n",
        "    discard_n = len(data_clean)-len(data_clean)//batch_size*batch_size\n",
        "    data_clean = np.delete(data_clean,range(discard_n),axis = 0)\n",
        "\n",
        "    print('-----training data finished-----')\n",
        "    print('noisy image shape:',data.shape)\n",
        "    print('clean image shape:',data_clean.shape)\n",
        "\n",
        "    assert data.shape == data_clean.shape\n",
        "\n",
        "\n",
        "    return data_clean, data"
      ],
      "metadata": {
        "id": "yi_PY1bO7vhz"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "def gen_speckled_image_patches(file_name):\n",
        "\n",
        "    last_name = file_name.split('_')[-1] #  Returns Name of the Image\n",
        "    clean_image_file_name = os.path.join(args.train_data_clean, last_name) # clean train image directory\n",
        "\n",
        "    img = cv2.imread(file_name, 0) # noisy image\n",
        "    clean_img = cv2.imread(clean_image_file_name, 0) # clean image\n",
        "\n",
        "    '''show(np.hstack((clean_img,img))) # display the images'''\n",
        "\n",
        "    h, w = img.shape\n",
        "\n",
        "    patches = []\n",
        "    clean_patches = []\n",
        "\n",
        "    for s in scales: # scaling the images\n",
        "        h_scaled, w_scaled = int(h*s),int(w*s)\n",
        "        img_scaled = cv2.resize(img, (h_scaled,w_scaled), interpolation=cv2.INTER_CUBIC)\n",
        "        clean_img_scaled = cv2.resize(clean_img, (h_scaled,w_scaled), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        # extract patches from the images '''ANEESH: PATCH 1 GETTING GENERATED'''\n",
        "        for i in range(0, h_scaled-patch_size+1, stride):\n",
        "            for j in range(0, w_scaled-patch_size+1, stride):\n",
        "                patch = img_scaled[i:i+patch_size, j:j+patch_size]\n",
        "                clean_patch = clean_img_scaled[i:i+patch_size, j:j+patch_size]\n",
        "\n",
        "                # data augmentation\n",
        "                for k in range(0, aug_times):\n",
        "                  mode_k=np.random.randint(0,8)\n",
        "                  patch_aug = data_augmentation(patch, mode=mode_k)\n",
        "                  clean_patch_aug = data_augmentation(clean_patch, mode=mode_k)\n",
        "                  patches.append(patch_aug)\n",
        "                  clean_patches.append(clean_patch_aug)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "    return clean_patches, patches"
      ],
      "metadata": {
        "id": "6ktmhpD-8xur"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Data Augmentation'''\n",
        "def data_augmentation(img, mode=0):\n",
        "    if mode == 0:\n",
        "        return img\n",
        "    elif mode == 1:\n",
        "        return np.flipud(img)\n",
        "    elif mode == 2:\n",
        "        return np.rot90(img)\n",
        "    elif mode == 3:\n",
        "        return np.flipud(np.rot90(img))\n",
        "    elif mode == 4:\n",
        "        return np.rot90(img, k=2)\n",
        "    elif mode == 5:\n",
        "        return np.flipud(np.rot90(img, k=2))\n",
        "    elif mode == 6:\n",
        "        return np.rot90(img, k=3)\n",
        "    elif mode == 7:\n",
        "        return np.flipud(np.rot90(img, k=3))"
      ],
      "metadata": {
        "id": "UAKj62Vp8bXU"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Show Images'''\n",
        "def show(x,title=None,cbar=False,figsize=None):\n",
        "    plt.figure(figsize=figsize)\n",
        "    plt.imshow(x,interpolation='nearest',cmap='gray')\n",
        "    if title:\n",
        "        plt.title(title)\n",
        "    if cbar:\n",
        "        plt.colorbar()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "KHhB2Ggv70Fd"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''Loss Function'''\n",
        "def sum_squared_error(y_true, y_pred):\n",
        "    #return K.mean(K.square(y_pred - y_true), axis=-1)\n",
        "    #return K.sum(K.square(y_pred - y_true), axis=-1)/2\n",
        "    return K.sum(K.square(y_pred - y_true))/2"
      ],
      "metadata": {
        "id": "uCsHTWNK78rr"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DIVA2D(depth, filters=64, image_channels=1, kernel_size=5, use_bnorm=True):\n",
        "    layer_count = 0\n",
        "    inpt = Input(shape=(None, None, image_channels), name='input'+str(layer_count))\n",
        "\n",
        "    # Get the initial patches\n",
        "    initial_patches = Conv2D(filters=filters, kernel_size=(kernel_size, kernel_size), strides=(1, 1),\n",
        "                             kernel_initializer='Orthogonal', padding='same', name='initial_patches')(inpt)\n",
        "    initial_patches = Activation('relu', name='initial_patch_acti')(initial_patches)\n",
        "\n",
        "    # Apply attention\n",
        "    initial_patches_with_attention = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=filters)(initial_patches, initial_patches)\n",
        "    initial_patches_with_attention = LayerNormalization()(initial_patches_with_attention + initial_patches)\n",
        "\n",
        "    # Interaction layer\n",
        "    inter = Conv2D(filters=filters, kernel_size=(kernel_size, kernel_size), strides=(1, 1),\n",
        "                   kernel_initializer='Orthogonal', padding='same', name='interactions')(initial_patches_with_attention)\n",
        "    inter = Activation('relu', name='interaction_acti'+str(layer_count))(inter)\n",
        "\n",
        "    # Get contributions of the original potential in the Hamiltonian kernel\n",
        "    ori_poten_kernel = MaxPooling2D(pool_size=(21, 21), strides=(15, 15), padding='same', name='ori_poten_ker')(initial_patches_with_attention)\n",
        "\n",
        "    # Get contributions of the interactions in the Hamiltonian kernel\n",
        "    inter_kernel = MaxPooling2D(pool_size=(21, 21), strides=(15, 15), padding='same', name='inter_ker')(inter)\n",
        "\n",
        "    # Get projection coefficients of the initial patches on the Hamiltonian kernel\n",
        "    x = Hamiltonian_Conv2D(filters=filters, kernel_size=(kernel_size, kernel_size), kernel_3=ori_poten_kernel,\n",
        "                           kernel_4=inter_kernel, strides=(1, 1), activation='relu',\n",
        "                           kernel_initializer='Orthogonal', padding='same', name='proj_coef')(initial_patches_with_attention)\n",
        "\n",
        "    # Thresholding\n",
        "    for i in range(depth):\n",
        "        layer_count += 1\n",
        "        x = Conv2D(filters=filters, kernel_size=(kernel_size, kernel_size), strides=(1, 1),\n",
        "                   kernel_initializer='Orthogonal', padding='same', use_bias=False, name='conv'+str(layer_count))(x)\n",
        "\n",
        "        layer_count += 1\n",
        "        x = BatchNormalization(axis=3, momentum=0.1, epsilon=0.0001, name='bn'+str(layer_count))(x)\n",
        "        x = Activation('relu', name='Thresholding'+str(layer_count))(x)\n",
        "\n",
        "    # Inverse projection\n",
        "    x = Conv2D(filters=image_channels, kernel_size=(kernel_size, kernel_size), strides=(1, 1),\n",
        "               kernel_initializer='Orthogonal', padding='same', use_bias=False, name='inv_trans')(x)\n",
        "\n",
        "    # Deconvolution layer\n",
        "    layer_count += 1\n",
        "    x = Conv2D(filters=filters, kernel_size=(kernel_size, kernel_size), strides=(1, 1),\n",
        "               kernel_initializer='Orthogonal', padding='same', use_bias=False, name='deconv'+str(layer_count))(x)\n",
        "    layer_count += 1\n",
        "    x = Conv2D(filters=filters, kernel_size=(kernel_size, kernel_size), strides=(1, 1),\n",
        "               kernel_initializer='Orthogonal', padding='same', use_bias=False, name='deconv'+str(layer_count))(x)\n",
        "    layer_count += 1\n",
        "    x = Conv2D(filters=image_channels, kernel_size=(kernel_size, kernel_size), strides=(1, 1),\n",
        "               kernel_initializer='Orthogonal', padding='same', use_bias=False, name='deconv'+str(layer_count))(x)\n",
        "    layer_count += 1\n",
        "\n",
        "    x = Subtract(name='subtract')([inpt, x])  # input - noise\n",
        "\n",
        "    model = Model(inputs=inpt, outputs=x)\n",
        "\n",
        "    return model"
      ],
      "metadata": {
        "id": "TJOxFp6R76eh"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "89Ajlpp5ueWM"
      },
      "outputs": [],
      "source": [
        " '''Hamiltonian convolution layer'''\n",
        "class Hamiltonian_Conv2D(Conv2D):\n",
        "\n",
        "    def __init__(self, filters, kernel_size, kernel_3=None, kernel_4=None, activation=None, use_bias = False, **kwargs):\n",
        "\n",
        "        self.rank = 2               # Dimension of the kernel\n",
        "        self.num_filters = filters  # Number of filter in the convolution layer\n",
        "        self.kernel_size = conv_utils.normalize_tuple(kernel_size, self.rank, 'kernel_size')\n",
        "        self.kernel_3 = kernel_3    # Weights from original potential\n",
        "        self.kernel_4 = kernel_4    # Weights from interaction\n",
        "\n",
        "        super(Hamiltonian_Conv2D, self).__init__(self.num_filters, self.kernel_size,\n",
        "              activation=activation, use_bias=False, **kwargs)\n",
        "\n",
        "    def build(self, input_shape):\n",
        "        if K.image_data_format() == 'channels_first':\n",
        "            channel_axis = 1\n",
        "        else:\n",
        "            channel_axis = -1\n",
        "        if input_shape[channel_axis] is None:\n",
        "            raise ValueError('The channel dimension of the inputs '\n",
        "                     'should be defined. Found `None`.')\n",
        "\n",
        "        #don't use bias:\n",
        "        self.bias = None\n",
        "\n",
        "        #consider the layer built\n",
        "        self.built = True\n",
        "\n",
        "\n",
        "        # Define nabla operator\n",
        "        weights_1 = tf.constant([[ 2.,-1., 0.],\n",
        "                                 [-1., 4.,-1.],\n",
        "                                 [ 0.,-1., 2.]])\n",
        "\n",
        "\n",
        "        weights_1 = tf.reshape(weights_1 , [3,3, 1])\n",
        "        weights_1 = tf.repeat(weights_1 , repeats=self.num_filters, axis=2)\n",
        "        #print('kernel shape of weights_1:',weights_1.get_shape())\n",
        "\n",
        "        # Define Weights for h^2/2m  (size should be same as the nabla operator)\n",
        "        weights_2 = self.add_weight(shape=weights_1.get_shape(),\n",
        "                                      initializer= 'Orthogonal',\n",
        "                                      name='kernel_h^2/2m',\n",
        "                                      regularizer=self.kernel_regularizer,\n",
        "                                      constraint=self.kernel_constraint)\n",
        "        #print('kernel shape of weights_2:',weights_2.get_shape())\n",
        "\n",
        "\n",
        "        # Define the Hamiltonian kernel\n",
        "        self.kernel = weights_1*weights_2 + self.kernel_3 + self.kernel_4\n",
        "        #print('self.kernel',self.kernel.get_shape())\n",
        "\n",
        "        self.built = True\n",
        "        super(Hamiltonian_Conv2D, self).build(input_shape)\n",
        "\n",
        "    # Do the 2D convolution using the Hamiltonian kernel\n",
        "    def convolution_op(self, inputs, kernel):\n",
        "        if self.padding == \"causal\":\n",
        "            tf_padding = \"VALID\"  # Causal padding handled in `call`.\n",
        "        elif isinstance(self.padding, str):\n",
        "            tf_padding = self.padding.upper()\n",
        "        else:\n",
        "            tf_padding = self.padding\n",
        "\n",
        "\n",
        "        return tf.nn.convolution(\n",
        "            inputs,\n",
        "            kernel,\n",
        "            strides=list(self.strides),\n",
        "            padding=tf_padding,\n",
        "            dilations=list(self.dilation_rate),\n",
        "            name=self.__class__.__name__,\n",
        "        )\n",
        "\n",
        "    def call(self, inputs):\n",
        "        outputs = self.convolution_op(inputs, self.kernel)\n",
        "        return outputs\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = DIVA2D(depth=15,filters=96,image_channels=1,use_bnorm=True)"
      ],
      "metadata": {
        "id": "oz0OteFv6AoF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "aNIHpeSg6KEH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "759f7ef5-0bc6-41d0-8092-1f4e0d8338de"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                Output Shape                 Param #   Connected to                  \n",
            "==================================================================================================\n",
            " input0 (InputLayer)         [(None, None, None, 1)]      0         []                            \n",
            "                                                                                                  \n",
            " initial_patches (Conv2D)    (None, None, None, 96)       2496      ['input0[0][0]']              \n",
            "                                                                                                  \n",
            " initial_patch_acti (Activa  (None, None, None, 96)       0         ['initial_patches[0][0]']     \n",
            " tion)                                                                                            \n",
            "                                                                                                  \n",
            " multi_head_attention (Mult  (None, None, None, 96)       148704    ['initial_patch_acti[0][0]',  \n",
            " iHeadAttention)                                                     'initial_patch_acti[0][0]']  \n",
            "                                                                                                  \n",
            " tf.__operators__.add (TFOp  (None, None, None, 96)       0         ['multi_head_attention[0][0]',\n",
            " Lambda)                                                             'initial_patch_acti[0][0]']  \n",
            "                                                                                                  \n",
            " layer_normalization (Layer  (None, None, None, 96)       192       ['tf.__operators__.add[0][0]']\n",
            " Normalization)                                                                                   \n",
            "                                                                                                  \n",
            " proj_coef (Hamiltonian_Con  (None, None, None, 96)       231264    ['layer_normalization[0][0]'] \n",
            " v2D)                                                                                             \n",
            "                                                                                                  \n",
            " conv1 (Conv2D)              (None, None, None, 96)       230400    ['proj_coef[0][0]']           \n",
            "                                                                                                  \n",
            " bn2 (BatchNormalization)    (None, None, None, 96)       384       ['conv1[0][0]']               \n",
            "                                                                                                  \n",
            " Thresholding2 (Activation)  (None, None, None, 96)       0         ['bn2[0][0]']                 \n",
            "                                                                                                  \n",
            " conv3 (Conv2D)              (None, None, None, 96)       230400    ['Thresholding2[0][0]']       \n",
            "                                                                                                  \n",
            " bn4 (BatchNormalization)    (None, None, None, 96)       384       ['conv3[0][0]']               \n",
            "                                                                                                  \n",
            " Thresholding4 (Activation)  (None, None, None, 96)       0         ['bn4[0][0]']                 \n",
            "                                                                                                  \n",
            " conv5 (Conv2D)              (None, None, None, 96)       230400    ['Thresholding4[0][0]']       \n",
            "                                                                                                  \n",
            " bn6 (BatchNormalization)    (None, None, None, 96)       384       ['conv5[0][0]']               \n",
            "                                                                                                  \n",
            " Thresholding6 (Activation)  (None, None, None, 96)       0         ['bn6[0][0]']                 \n",
            "                                                                                                  \n",
            " conv7 (Conv2D)              (None, None, None, 96)       230400    ['Thresholding6[0][0]']       \n",
            "                                                                                                  \n",
            " bn8 (BatchNormalization)    (None, None, None, 96)       384       ['conv7[0][0]']               \n",
            "                                                                                                  \n",
            " Thresholding8 (Activation)  (None, None, None, 96)       0         ['bn8[0][0]']                 \n",
            "                                                                                                  \n",
            " conv9 (Conv2D)              (None, None, None, 96)       230400    ['Thresholding8[0][0]']       \n",
            "                                                                                                  \n",
            " bn10 (BatchNormalization)   (None, None, None, 96)       384       ['conv9[0][0]']               \n",
            "                                                                                                  \n",
            " Thresholding10 (Activation  (None, None, None, 96)       0         ['bn10[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv11 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding10[0][0]']      \n",
            "                                                                                                  \n",
            " bn12 (BatchNormalization)   (None, None, None, 96)       384       ['conv11[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding12 (Activation  (None, None, None, 96)       0         ['bn12[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv13 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding12[0][0]']      \n",
            "                                                                                                  \n",
            " bn14 (BatchNormalization)   (None, None, None, 96)       384       ['conv13[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding14 (Activation  (None, None, None, 96)       0         ['bn14[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv15 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding14[0][0]']      \n",
            "                                                                                                  \n",
            " bn16 (BatchNormalization)   (None, None, None, 96)       384       ['conv15[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding16 (Activation  (None, None, None, 96)       0         ['bn16[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv17 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding16[0][0]']      \n",
            "                                                                                                  \n",
            " bn18 (BatchNormalization)   (None, None, None, 96)       384       ['conv17[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding18 (Activation  (None, None, None, 96)       0         ['bn18[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv19 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding18[0][0]']      \n",
            "                                                                                                  \n",
            " bn20 (BatchNormalization)   (None, None, None, 96)       384       ['conv19[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding20 (Activation  (None, None, None, 96)       0         ['bn20[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv21 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding20[0][0]']      \n",
            "                                                                                                  \n",
            " bn22 (BatchNormalization)   (None, None, None, 96)       384       ['conv21[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding22 (Activation  (None, None, None, 96)       0         ['bn22[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv23 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding22[0][0]']      \n",
            "                                                                                                  \n",
            " bn24 (BatchNormalization)   (None, None, None, 96)       384       ['conv23[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding24 (Activation  (None, None, None, 96)       0         ['bn24[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv25 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding24[0][0]']      \n",
            "                                                                                                  \n",
            " bn26 (BatchNormalization)   (None, None, None, 96)       384       ['conv25[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding26 (Activation  (None, None, None, 96)       0         ['bn26[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv27 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding26[0][0]']      \n",
            "                                                                                                  \n",
            " bn28 (BatchNormalization)   (None, None, None, 96)       384       ['conv27[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding28 (Activation  (None, None, None, 96)       0         ['bn28[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " conv29 (Conv2D)             (None, None, None, 96)       230400    ['Thresholding28[0][0]']      \n",
            "                                                                                                  \n",
            " bn30 (BatchNormalization)   (None, None, None, 96)       384       ['conv29[0][0]']              \n",
            "                                                                                                  \n",
            " Thresholding30 (Activation  (None, None, None, 96)       0         ['bn30[0][0]']                \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " inv_trans (Conv2D)          (None, None, None, 1)        2400      ['Thresholding30[0][0]']      \n",
            "                                                                                                  \n",
            " deconv31 (Conv2D)           (None, None, None, 96)       2400      ['inv_trans[0][0]']           \n",
            "                                                                                                  \n",
            " deconv32 (Conv2D)           (None, None, None, 96)       230400    ['deconv31[0][0]']            \n",
            "                                                                                                  \n",
            " deconv33 (Conv2D)           (None, None, None, 1)        2400      ['deconv32[0][0]']            \n",
            "                                                                                                  \n",
            " subtract (Subtract)         (None, None, None, 1)        0         ['input0[0][0]',              \n",
            "                                                                     'deconv33[0][0]']            \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 4082016 (15.57 MB)\n",
            "Trainable params: 4079136 (15.56 MB)\n",
            "Non-trainable params: 2880 (11.25 KB)\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''Hyperparameters'''\n",
        "patch_size, stride = 50, 10\n",
        "aug_times = 1\n",
        "scales = [1] # [1, 0.9, 0.8, 0.7]\n",
        "batch_size = 10"
      ],
      "metadata": {
        "id": "P5k_OuLm7o6H"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == '__main__':\n",
        "    # model selection\n",
        "    model = DIVA2D(depth=15,filters=96,image_channels=1,use_bnorm=True)\n",
        "    #model.summary()\n",
        "\n",
        "    # load the last model in matconvnet style\n",
        "    initial_epoch = findLastCheckpoint(save_dir=save_dir)\n",
        "    if initial_epoch > 0:\n",
        "        print('resuming by loading epoch %03d'%initial_epoch)\n",
        "        model.load_weights(os.path.join(save_dir,'model_%03d.hdf5'%initial_epoch))\n",
        "\n",
        "    # compile the model\n",
        "    model.compile(optimizer=Adam(0.001), loss= tf.keras.losses.MeanSquaredError(), #tf.keras.losses.CosineSimilarity (axis=-1, reduction=\"auto\", name=\"cosine_similarity\"),\n",
        "                  metrics=[tf.keras.metrics.MeanSquaredError(),\n",
        "                           tf.keras.metrics.RootMeanSquaredError(),\n",
        "                           tf.keras.metrics.MeanSquaredLogarithmicError(),\n",
        "                           tf.keras.metrics.MeanAbsoluteError(),\n",
        "                           sum_squared_error])\n",
        "\n",
        "    # tf.keras.metrics.MeanAbsolutePercentageError(), tf.keras.metrics.CosineSimilarity(name=\"cosine_similarity\", dtype=None, axis=-1),\n",
        "    # tf.keras.metrics.LogCoshError(),\n",
        "\n",
        "    # use call back functions\n",
        "    checkpointer = ModelCheckpoint(os.path.join(save_dir,'model_{epoch:03d}.hdf5'),\n",
        "                verbose=1, save_weights_only=False, period=1)\n",
        "    csv_logger = CSVLogger(os.path.join(save_dir,'log.csv'), append=True, separator=',')\n",
        "    lr_scheduler = LearningRateScheduler(lr_schedule)\n",
        "\n",
        "    print('batch_size = ',args.batch_size)\n",
        "    history = model.fit(train_datagen(batch_size=args.batch_size),\n",
        "                steps_per_epoch=1500, epochs=5, verbose=1, initial_epoch=initial_epoch,\n",
        "                callbacks=[checkpointer,csv_logger,lr_scheduler])\n",
        "    #steps_per_epoch = 7000, epochs = 50"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxqNGvHd7-zY",
        "outputId": "8adace33-4a01-4e04-bbd8-fbf58025698c"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "batch_size =  10\n",
            "-----training data finished-----\n",
            "noisy image shape: (13690, 50, 50, 1)\n",
            "clean image shape: (13690, 50, 50, 1)\n",
            "2024-04-19 15:14:53: current learning rate is 0.00100000\n",
            "Epoch 1/5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Gradients do not exist for variables ['proj_coef/kernel_h^2/2m:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['proj_coef/kernel_h^2/2m:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['proj_coef/kernel_h^2/2m:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
            "WARNING:tensorflow:Gradients do not exist for variables ['proj_coef/kernel_h^2/2m:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1500/1500 [==============================] - ETA: 0s - loss: 0.1112 - mean_squared_error: 0.1112 - root_mean_squared_error: 0.3335 - mean_squared_logarithmic_error: 0.0155 - mean_absolute_error: 0.1269 - sum_squared_error: 1390.4016\n",
            "Epoch 1: saving model to /content/my_drive/MyDrive/DIVA-Attention Test/Deep_DeQuIP_Attn/model_001.hdf5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r1500/1500 [==============================] - 488s 315ms/step - loss: 0.1112 - mean_squared_error: 0.1112 - root_mean_squared_error: 0.3335 - mean_squared_logarithmic_error: 0.0155 - mean_absolute_error: 0.1269 - sum_squared_error: 1390.4016 - lr: 0.0010\n",
            "2024-04-19 15:23:01: current learning rate is 0.00100000\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - ETA: 0s - loss: 0.0174 - mean_squared_error: 0.0174 - root_mean_squared_error: 0.1318 - mean_squared_logarithmic_error: 0.0099 - mean_absolute_error: 0.1020 - sum_squared_error: 217.2446\n",
            "Epoch 2: saving model to /content/my_drive/MyDrive/DIVA-Attention Test/Deep_DeQuIP_Attn/model_002.hdf5\n",
            "1500/1500 [==============================] - 473s 315ms/step - loss: 0.0174 - mean_squared_error: 0.0174 - root_mean_squared_error: 0.1318 - mean_squared_logarithmic_error: 0.0099 - mean_absolute_error: 0.1020 - sum_squared_error: 217.2446 - lr: 0.0010\n",
            "2024-04-19 15:30:54: current learning rate is 0.00100000\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - ETA: 0s - loss: 0.0118 - mean_squared_error: 0.0118 - root_mean_squared_error: 0.1085 - mean_squared_logarithmic_error: 0.0068 - mean_absolute_error: 0.0815 - sum_squared_error: 147.1327\n",
            "Epoch 3: saving model to /content/my_drive/MyDrive/DIVA-Attention Test/Deep_DeQuIP_Attn/model_003.hdf5\n",
            "1500/1500 [==============================] - 475s 317ms/step - loss: 0.0118 - mean_squared_error: 0.0118 - root_mean_squared_error: 0.1085 - mean_squared_logarithmic_error: 0.0068 - mean_absolute_error: 0.0815 - sum_squared_error: 147.1327 - lr: 0.0010\n",
            "2024-04-19 15:38:49: current learning rate is 0.00100000\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - ETA: 0s - loss: 0.0091 - mean_squared_error: 0.0091 - root_mean_squared_error: 0.0952 - mean_squared_logarithmic_error: 0.0053 - mean_absolute_error: 0.0697 - sum_squared_error: 113.2150\n",
            "Epoch 4: saving model to /content/my_drive/MyDrive/DIVA-Attention Test/Deep_DeQuIP_Attn/model_004.hdf5\n",
            "1500/1500 [==============================] - 475s 317ms/step - loss: 0.0091 - mean_squared_error: 0.0091 - root_mean_squared_error: 0.0952 - mean_squared_logarithmic_error: 0.0053 - mean_absolute_error: 0.0697 - sum_squared_error: 113.2150 - lr: 0.0010\n",
            "2024-04-19 15:46:44: current learning rate is 0.00100000\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - ETA: 0s - loss: 0.0080 - mean_squared_error: 0.0080 - root_mean_squared_error: 0.0893 - mean_squared_logarithmic_error: 0.0047 - mean_absolute_error: 0.0646 - sum_squared_error: 99.6557\n",
            "Epoch 5: saving model to /content/my_drive/MyDrive/DIVA-Attention Test/Deep_DeQuIP_Attn/model_005.hdf5\n",
            "1500/1500 [==============================] - 475s 317ms/step - loss: 0.0080 - mean_squared_error: 0.0080 - root_mean_squared_error: 0.0893 - mean_squared_logarithmic_error: 0.0047 - mean_absolute_error: 0.0646 - sum_squared_error: 99.6557 - lr: 0.0010\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''saves the history of the model as a binary file'''\n",
        "import pickle\n",
        "\n",
        "# Save history to a file\n",
        "with open('/content/my_drive/MyDrive/CNRS Research/Deep_DeQuIP_100_F/training_history.pkl', 'wb') as file:\n",
        "    pickle.dump(history.history, file)"
      ],
      "metadata": {
        "id": "h3AhxsrTlJXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# list all data in history\n",
        "print(history.history.keys())\n",
        "# summarize history for loss\n",
        "#plt.plot((history.history['loss']))\n",
        "plt.plot((history.history['mean_squared_error']))\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'test'], loc='upper right')\n",
        "plt.show()\n",
        "#1622.84 min sum_square_error -> v1 train 50 epoch, 2500 steps, 256 batches"
      ],
      "metadata": {
        "id": "L38p0S5rwJy_",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "outputId": "74f7ae97-4086-4a46-d2aa-e72b5a22905e"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "dict_keys(['loss', 'mean_squared_error', 'root_mean_squared_error', 'mean_squared_logarithmic_error', 'mean_absolute_error', 'sum_squared_error', 'lr'])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import runtime\n",
        "runtime.unassign()"
      ],
      "metadata": {
        "id": "9PnoCdQIgIqo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "0OBooABHuWW_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}